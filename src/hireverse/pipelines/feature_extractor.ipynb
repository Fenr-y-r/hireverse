{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "participant_id = \"P1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hireverse.utils.utils import *\n",
    "\n",
    "VID_FILE_PATH = BASE_DIR + \"/data/raw/videos\"\n",
    "OUTPUT_CSV_FILE = BASE_DIR + \"/data/processed/interview_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hireverse.utils.face_analyzer import FaceAnalyzer\n",
    "\n",
    "face_analyzer = FaceAnalyzer()\n",
    "frames = face_analyzer.get_video_frames_for_participant(\n",
    "    participant_id, VID_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.LexicalAnalyser import LexicalAnalyser\n",
    "\n",
    "# AUDIO_FILE_PATH = f\"../../data/raw/audio/trimmed_{participant_id}.wav\"\n",
    "# lexical_analyser = LexicalAnalyser(AUDIO_FILE_PATH)\n",
    "# # Extract all features\n",
    "# lexical_features = lexical_analyser.extract_all_features()\n",
    "\n",
    "# # Print the extracted features\n",
    "# print(lexical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hireverse.schemas.frame import Frame\n",
    "\n",
    "\n",
    "filtered_frames: List[Frame] = []\n",
    "for frame in frames:\n",
    "    frame.facial_landmarks_obj = face_analyzer.process_image_results(frame.image)\n",
    "    if frame.facial_landmarks_obj:\n",
    "        frame.facial_landmarks = frame.facial_landmarks_obj.landmark\n",
    "        filtered_frames.append(frame)\n",
    "\n",
    "frames = filtered_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    if frame.facial_landmarks:\n",
    "        frame.face = face_analyzer.get_face_coordinates(frame.facial_landmarks, frame.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(frames)-1):\n",
    "    bbox1 =face_analyzer.get_bouding_box_center(frames[i].face)\n",
    "    bbox2= face_analyzer.get_bouding_box_center(frames[i+1].face)\n",
    "    frames[i].head_displacement = face_analyzer.get_displacement_between_two_bounding_boxes(bbox1, bbox2)\n",
    "    frames[i].head_vertical_displacement = face_analyzer.get_vertical_displacement_between_two_bounding_boxes(bbox1, bbox2)\n",
    "    frames[i].head_horizontal_displacement = face_analyzer.get_horizontal_distance_between_two_bounding_boxes(bbox1, bbox2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# SMOOTH_WINDOW = 5\n",
    "# happiness_buffer = []\n",
    "# def smooth_happiness(happiness_prob):\n",
    "#     if happiness_prob is None:\n",
    "#         return 0 # TODO: change?\n",
    "#     happiness_buffer.append(happiness_prob)\n",
    "#     if len(happiness_buffer) > SMOOTH_WINDOW:\n",
    "#         happiness_buffer.pop(0)\n",
    "#     return np.mean(happiness_buffer)\n",
    "\n",
    "\n",
    "# for i, frame in enumerate(frames):\n",
    "#     face_roi = face_analyzer.get_face_roi_image(frame.image, frame.face, expand_ratio=1.1)\n",
    "#     frame.smile = smooth_happiness(face_analyzer.get_smile_from_frame(face_roi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Facial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for frame in frames:\n",
    "#     frame.two_landmarks_connectors = face_analyzer.get_selected_facial_landmarks(frame.facial_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# for frame in frames:\n",
    "#     result = face_analyzer.get_face_angles(frame.image, frame.facial_landmarks)\n",
    "#     frame.face_angles = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosodic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProsodicFeatures(f0_mean=138.8311168142939, f0_min=75.34559605984698, f0_max=599.1469508185926, f0_range=523.8013547587456, f0_sd=67.08530112931376, intensity_mean=-17.989479064941406, intensity_min=-36.43029022216797, intensity_max=0.0, intensity_range=36.43029022216797, intensity_sd=7.597977638244629, f1_mean=626.2173706460609, f1_sd=255.618004717988, f2_mean=1801.0016796933116, f2_sd=369.19335979732216, f3_mean=2718.6018206978147, f3_sd=363.6766279398512, f2_f1_mean=3.2093469178503944, f3_f1_mean=4.813353523730503, f2_f1_sd=1.1984938994193113, f3_f1_sd=1.5116794397601092, jitter=0.02250039669976796, shimmer=0.17853661247111466, percent_unvoiced=14.22418608114985, percent_breaks=1.6075754239154016, max_pause_duration=2.429999999999999, avg_pause_duration=0.31397260273972616, duration=161.134)\n"
     ]
    }
   ],
   "source": [
    "from hireverse.schemas.model_features import ProsodicFeatures\n",
    "from hireverse.utils.prosody_analyzer import ProsodyAnalyzer\n",
    "\n",
    "prosody_analyzer = ProsodyAnalyzer(participant_id)\n",
    "prosodic_features: ProsodicFeatures = prosody_analyzer.extract_all_features()\n",
    "print(prosodic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial Features Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Frame' object has no attribute 'two_landmarks_connectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhireverse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_storage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureStorage\n\u001b[1;32m      3\u001b[0m feature_storage \u001b[38;5;241m=\u001b[39m FeatureStorage(OUTPUT_CSV_FILE)\n\u001b[0;32m----> 4\u001b[0m facial_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_facial_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personal_projects/hireverse/src/hireverse/utils/feature_storage.py:53\u001b[0m, in \u001b[0;36mFeatureStorage.aggregate_facial_features\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maggregate_facial_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, frames: \u001b[38;5;28mlist\u001b[39m[Frame]):\n\u001b[0;32m---> 53\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_two_landmark_connectors_features_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Initialize feature lists\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     feature_lists \u001b[38;5;241m=\u001b[39m {name: [] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m feature_names}\n",
      "File \u001b[0;32m~/personal_projects/hireverse/src/hireverse/utils/feature_storage.py:46\u001b[0m, in \u001b[0;36mFeatureStorage._get_two_landmark_connectors_features_names\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_two_landmark_connectors_features_names\u001b[39m(\u001b[38;5;28mself\u001b[39m, frames: \u001b[38;5;28mlist\u001b[39m[Frame]):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames:\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtwo_landmarks_connectors\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m             feature_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     48\u001b[0m                 connector\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m connector \u001b[38;5;129;01min\u001b[39;00m frame\u001b[38;5;241m.\u001b[39mtwo_landmarks_connectors\n\u001b[1;32m     49\u001b[0m             ]\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m feature_names\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Frame' object has no attribute 'two_landmarks_connectors'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from hireverse.utils.feature_storage import FeatureStorage\n",
    "\n",
    "feature_storage = FeatureStorage(OUTPUT_CSV_FILE)\n",
    "facial_features = feature_storage.aggregate_facial_features(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_storage.save_to_csv(participant_id, facial_features, prosodic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for frame in frames:\n",
    "#     frame.reset_drawable_image()\n",
    "#     # frame.draw_face_border()\n",
    "    \n",
    "#     frame.draw_selected_facial_landmarks(draw_lines=True)\n",
    "    \n",
    "#     frame.put_face_angles()\n",
    "#     # frame.draw_facial_landmarks()\n",
    "#     frame.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
