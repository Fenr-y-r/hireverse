{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "target_column = \"RecommendHiring\"\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "VIDEOS_FOLDER = \"./data/raw/videos\"\n",
        "import importlib.util\n",
        "from pathlib import Path\n",
        "import os\n",
        "analyzer_paths = Path(\"./src/utils\").resolve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "SCRIPT_DIR = os.path.join(os.getcwd(),)\n",
        "\n",
        "SAVED_MODELS_PATH=\"./saved models\"\n",
        "\n",
        "DROPPED_LEXICAL_COLUMNS = [\n",
        "    \"Swear\",\n",
        "    \"Numbers\",\n",
        "    \"Inhibition\",\n",
        "    \"Preceptual\",\n",
        "    \"Anxiety\",\n",
        "    \"Anger\",\n",
        "    \"Sadness\",\n",
        "    \"Work\",\n",
        "    \"Articles\",\n",
        "    \"Verbs\",\n",
        "    \"Adverbs\",\n",
        "    \"Prepositions\",\n",
        "    \"Conjunctions\",\n",
        "    \"Negations\",\n",
        "]\n",
        "\n",
        "facial_features = [\n",
        "    \"average_inner_brow_height\",\n",
        "    \"average_outer_brow_height\",\n",
        "    \"eye_open\",\n",
        "    \"inner_lip_height\",\n",
        "    \"lip_corner_distance\",\n",
        "    \"outer_lip_height\",\n",
        "    \"smile\",\n",
        "    \"pitch\",\n",
        "    \"roll\",\n",
        "    \"yaw\",\n",
        "]\n",
        "\n",
        "stats = [\"max\", \"median\", \"min\", \"std\"]\n",
        "DROPPED_FACIAL_FEATURES = [\n",
        "    f\"{feature}_{stat}\" for feature in facial_features for stat in stats\n",
        "]\n",
        "\n",
        "\n",
        "DROPPED_PROSODIC_COLUMNS = []\n",
        "\n",
        "ALREADY_NORMALIZED_FEATURES = [\n",
        "    \"average_outer_brow_height_mean\",\n",
        "    \"average_inner_brow_height_mean\",\n",
        "    \"eye_open_mean\",\n",
        "    \"inner_lip_height_mean\",\n",
        "    \"inner_lip_height_mean\",\n",
        "    \"lip_corner_distance_mean\",\n",
        "    \"average_outer_brow_height_std\",\n",
        "    \"average_inner_brow_height_std\",\n",
        "    \"eye_open_std\",\n",
        "    \"outer_lip_height_std\",\n",
        "    \"inner_lip_height_std\",\n",
        "    \"lip_corner_distance_std\",\n",
        "    \"average_outer_brow_height_min\",\n",
        "    \"average_inner_brow_height_min\",\n",
        "    \"eye_open_min\",\n",
        "    \"outer_lip_height_min\",\n",
        "    \"inner_lip_height_min\",\n",
        "    \"lip_corner_distance_min\",\n",
        "    \"average_outer_brow_height_max\",\n",
        "    \"average_inner_brow_height_max\",\n",
        "    \"eye_open_max\",\n",
        "    \"outer_lip_height_max\",\n",
        "    \"inner_lip_height_max\",\n",
        "    \"lip_corner_distance_max\",\n",
        "    \"average_outer_brow_height_median\",\n",
        "    \"average_inner_brow_height_median\",\n",
        "    \"eye_open_median\",\n",
        "    \"outer_lip_height_median\",\n",
        "    \"inner_lip_height_median\",\n",
        "    \"lip_corner_distance_median\",\n",
        "]  # these are already in [0, 1]\n",
        "\n",
        "MUST_KEEP_FEATURES = [\n",
        "    \"pause_duration_avg\",\n",
        "    \"average_outer_brow_height_mean\",\n",
        "    \"average_inner_brow_height_mean\",\n",
        "    \"outer_lip_height_mean\",\n",
        "    \"Duration/Filler Words\",\n",
        "]\n",
        "\n",
        "\n",
        "GROUPS_COLUMN = \"cleaned_ids\"\n",
        "INDEX_COLUMN = \"participant_id\"\n",
        "\n",
        "\n",
        "def pearson_corr(y_true, y_pred):\n",
        "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
        "\n",
        "\n",
        "SCORING_METRICS = {\n",
        "    \"r2\": \"r2\",\n",
        "    \"mae\": \"neg_mean_absolute_error\",\n",
        "    \"pearson\": make_scorer(pearson_corr),  # Pearson Correlation Coefficient\n",
        "}\n",
        "\n",
        "\n",
        "MUST_KEEP_FEATURES = [\n",
        "    # \"pause_duration_avg\",\n",
        "    # \"average_outer_brow_height_mean\",\n",
        "    # \"average_inner_brow_height_mean\",\n",
        "    # \"outer_lip_height_mean\",\n",
        "    \"Duration/Filler Words\",\n",
        "]\n",
        "\n",
        "PIPELINE_PARAMS = {'feature_selection__estimator__alpha': 0.057376790661083456, 'svr__C': 0.655379988356498, 'svr__gamma': 0.02784736494309893, 'svr__epsilon': 0.2617249201838037, 'svr__kernel': 'rbf'}\n",
        "HYPERPARAMETER_TUNING_ENABLED = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "features_df = pd.read_csv(\"../../data/external/add.csv\")\n",
        "features_df = features_df.set_index(\"participant_id\")\n",
        "\n",
        "labels_df = pd.read_csv(\n",
        "    os.path.join(\"../../data/external/turker_scores_full_interview.csv\")\n",
        ")\n",
        "labels_df = labels_df.set_index(\"Participant\")\n",
        "labels_df = labels_df.loc[labels_df[\"Worker\"] == \"AGGR\"]\n",
        "\n",
        "features_df.index = features_df.index.str.lower()\n",
        "labels_df.index = labels_df.index.str.lower()\n",
        "indexed_combined_df = features_df.join(labels_df[[target_column]], how=\"left\")\n",
        "combined_df = indexed_combined_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = combined_df.drop(columns=[target_column, GROUPS_COLUMN])\n",
        "y = combined_df[target_column]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score, cross_validate\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import models.domain_aware_selector\n",
        "groups_column = combined_df[GROUPS_COLUMN].astype(str).values\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        ('dropper', 'drop', DROPPED_FACIAL_FEATURES + \n",
        "                            DROPPED_LEXICAL_COLUMNS + \n",
        "                            DROPPED_PROSODIC_COLUMNS)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "unfitted_pipeline = Pipeline(\n",
        "    [\n",
        "        ('preprocessor', preprocessor),\n",
        "        (\"imputer\", SimpleImputer(strategy=\"mean\")),  # NaN imputation\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feature_selection\", SelectFromModel(estimator=Lasso(max_iter=50000), )),\n",
        "        # ('feature_selection', DomainAwareSelector(\n",
        "        #     must_keep_features=MUST_KEEP_FEATURES,\n",
        "        #     selector=SelectFromModel(lasso_feature_selection_model, max_features=10),\n",
        "        # )),\n",
        "        (\"svr\", SVR(kernel=\"rbf\")),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import GroupShuffleSplit, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "def objective(trial):\n",
        "    pipeline_clone = clone(unfitted_pipeline)  # Clone pipeline for thread safety\n",
        "    \n",
        "    params = {\n",
        "        \"feature_selection__estimator__alpha\": trial.suggest_float(\n",
        "        \"feature_selection__estimator__alpha\", 1e-4, 0.1, log=True  # Adjusted lower bound\n",
        "        ),\n",
        "        \"svr__C\": trial.suggest_float(\"svr__C\", 0.01, 100, log=True),\n",
        "        \"svr__gamma\": trial.suggest_float(\"svr__gamma\", 1e-3, 1e1, log=True),\n",
        "        \"svr__epsilon\": trial.suggest_float(\"svr__epsilon\", 0.01, 0.5),\n",
        "        \"svr__kernel\": trial.suggest_categorical(\"svr__kernel\", [\"rbf\"\n",
        "                                                                #  , \"poly\"\n",
        "                                                                 ]),\n",
        "    }\n",
        "    \n",
        "    # if params[\"svr__kernel\"] == \"poly\":\n",
        "    #     params[\"svr__degree\"] = trial.suggest_int(\"svr__degree\", 2, 3)  # Reduced from 5\n",
        "    #     params[\"svr__coef0\"] = trial.suggest_float(\"svr__coef0\", 0.0, 0.5)  # Narrower range\n",
        "        \n",
        "    pipeline_clone.set_params(**params)\n",
        "    \n",
        "    mc_cv_tuning = GroupShuffleSplit(n_splits=20, test_size=0.2, random_state=42)\n",
        "    \n",
        "    scores = cross_val_score(\n",
        "        pipeline_clone, X, y, cv=mc_cv_tuning, groups=groups_column, n_jobs=1\n",
        "    )\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "if HYPERPARAMETER_TUNING_ENABLED:\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100, n_jobs=-1, timeout=4*60)\n",
        "    \n",
        "    print(\"Best hyperparameters:\", study.best_params)\n",
        "    print(f\"Best R² score: {study.best_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Store Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import clone\n",
        "\n",
        "if HYPERPARAMETER_TUNING_ENABLED:\n",
        "    unfitted_pipeline.set_params(**study.best_params)\n",
        "else:\n",
        "    unfitted_pipeline.set_params(**PIPELINE_PARAMS)\n",
        "fitted_pipeline = clone(unfitted_pipeline)\n",
        "fitted_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessor = fitted_pipeline.named_steps['preprocessor']\n",
        "feature_names = preprocessor.get_feature_names_out()    # after preprocessing\n",
        "\n",
        "feature_selector = fitted_pipeline.named_steps['feature_selection']\n",
        "selected_mask = feature_selector.get_support()\n",
        "\n",
        "selected_features = feature_names[selected_mask]\n",
        "unselected_features = feature_names[~selected_mask]\n",
        "\n",
        "print(f\"Number of Selected features ({len(selected_features)}):\")\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "print(f\"Unselected features: {unselected_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Monte Carlo Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "scoring = {\n",
        "    \"r2\": make_scorer(r2_score),\n",
        "    \"pearson\": make_scorer(pearson_corr)\n",
        "}\n",
        "\n",
        "results = cross_validate(\n",
        "    unfitted_pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=GroupShuffleSplit(n_splits=1000, test_size=0.2, random_state=42),\n",
        "    groups=groups_column,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "r2_scores = results[\"test_r2\"]\n",
        "pearson_scores = results[\"test_pearson\"]\n",
        "# Report the average performance and variability\n",
        "avg_r2_score = np.mean(r2_scores)\n",
        "print(\n",
        "    f\"Mean R² Score: {avg_r2_score:.2f} (±{np.std(r2_scores):.2f})\"\n",
        ")\n",
        "avg_perason_score = np.mean(pearson_scores)\n",
        "print(\n",
        "    f\"Mean Pearson Correlation: {avg_perason_score:.2f} (±{np.std(pearson_scores):.2f})\"\n",
        ")\n",
        "\n",
        "# Mean R² Score: 0.20 (±0.23)\n",
        "# Mean Pearson Correlation: 0.53 (±0.16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(fitted_pipeline, os.path.join(SAVED_MODELS_PATH,f'{target_column}.joblib'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
