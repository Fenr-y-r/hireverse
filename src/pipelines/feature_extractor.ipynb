{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "participant_id = \"P1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from utils.utils import *\n",
    "\n",
    "VID_FILE_PATH = MAIN_DIR + \"/data/raw/videos\"\n",
    "OUTPUT_CSV_FILE = MAIN_DIR + \"/data/processed/interview_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.face_analyzer import FaceAnalyzer\n",
    "\n",
    "face_analyzer = FaceAnalyzer()\n",
    "frames = face_analyzer.get_video_frames_for_participant(\n",
    "    participant_id, VID_FILE_PATH, num_selected_frames=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.LexicalAnalyser import LexicalAnalyser\n",
    "\n",
    "# AUDIO_FILE_PATH = f\"../../data/raw/audio/trimmed_{participant_id}.wav\"\n",
    "# lexical_analyser = LexicalAnalyser(AUDIO_FILE_PATH)\n",
    "# # Extract all features\n",
    "# lexical_features = lexical_analyser.extract_all_features()\n",
    "\n",
    "# # Print the extracted features\n",
    "# print(lexical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    detected_faces_landmarks = face_analyzer.process_image_results(frame.image)\n",
    "    frame.facial_landmarks_obj= face_analyzer.get_largest_face_landmarks_obj(frame.image, detected_faces_landmarks)\n",
    "    if frame.facial_landmarks_obj:\n",
    "        frame.facial_landmarks = frame.facial_landmarks_obj.landmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for frame in frames:\n",
    "    if frame.facial_landmarks:\n",
    "        frame.face = face_analyzer.get_face_coordinates(frame.facial_landmarks, frame.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "SMOOTH_WINDOW = 5\n",
    "happiness_buffer = []\n",
    "def smooth_happiness(happiness_prob):\n",
    "    if happiness_prob is None:\n",
    "        return 0 # TODO: change?\n",
    "    happiness_buffer.append(happiness_prob)\n",
    "    if len(happiness_buffer) > SMOOTH_WINDOW:\n",
    "        happiness_buffer.pop(0)\n",
    "    return np.mean(happiness_buffer)\n",
    "\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    face_roi = face_analyzer.get_face_roi_image(frame.image, frame.face, expand_ratio=1.1)\n",
    "    frame.smile = smooth_happiness(face_analyzer.get_smile_from_frame(face_roi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Facial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    frame.two_landmarks_connectors = face_analyzer.get_selected_facial_landmarks(frame.facial_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for frame in frames:\n",
    "    result = face_analyzer.get_face_angles(frame.image, frame.facial_landmarks)\n",
    "    frame.face_angles = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosodic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schemas.model_features import ProsodicFeatures\n",
    "from utils.prosody_analyzer import ProsodyAnalyzer\n",
    " \n",
    "\n",
    "prosody_analyzer = ProsodyAnalyzer(participant_id)\n",
    "prosodic_features: ProsodicFeatures = prosody_analyzer.extract_all_features()\n",
    "print(prosodic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial Features Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.feature_storage import FeatureStorage\n",
    "\n",
    "\n",
    "feature_storage = FeatureStorage(OUTPUT_CSV_FILE)\n",
    "facial_features = feature_storage.aggregate_facial_features(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature attributes: {'average_outer_brow_height_mean': 0.016292900807397526, 'average_inner_brow_height_mean': 0.016716919456475587, 'eye_open_mean': 0.010468848209014529, 'outer_lip_height_mean': 0.018316188260899348, 'inner_lip_height_mean': 0.0015409458352216691, 'lip_corner_distance_mean': 0.0440151939977027, 'smile_mean': 10.256666666666668, 'pitch_mean': -4.712518372137046, 'yaw_mean': 3.0347174116061266, 'roll_mean': 6.353102566850139, 'average_outer_brow_height_std': 0.0012285257356963754, 'average_inner_brow_height_std': 0.0020765351662113078, 'eye_open_std': 0.002062652254566344, 'outer_lip_height_std': 0.002059701403088427, 'inner_lip_height_std': 0.0010092618753403165, 'lip_corner_distance_std': 0.0019574266099187283, 'smile_std': 11.420198480470178, 'pitch_std': 3.3918804800803084, 'yaw_std': 7.172205755936284, 'roll_std': 4.98795219956107, 'average_outer_brow_height_min': 0.014478190489122942, 'average_inner_brow_height_min': 0.014040496248951373, 'eye_open_min': 0.007808025736488998, 'outer_lip_height_min': 0.014147809735884549, 'inner_lip_height_min': 0.00027988240634184316, 'lip_corner_distance_min': 0.03956649792768467, 'smile_min': 0.0, 'pitch_min': -10.293237028635312, 'yaw_min': -9.2033529674856, 'roll_min': -5.5839768822184555, 'average_outer_brow_height_max': 0.018995114746135848, 'average_inner_brow_height_max': 0.021689080981890204, 'eye_open_max': 0.013506450618906101, 'outer_lip_height_max': 0.02320168223899964, 'inner_lip_height_max': 0.004898038388114329, 'lip_corner_distance_max': 0.04720541280950892, 'smile_max': 35.0, 'pitch_max': 4.541264200059321, 'yaw_max': 21.41375807799979, 'roll_max': 13.05921694495837, 'average_outer_brow_height_median': 0.015739197010792082, 'average_inner_brow_height_median': 0.015979444736464357, 'eye_open_median': 0.009505209102181517, 'outer_lip_height_median': 0.018292484822983242, 'inner_lip_height_median': 0.001388473587979168, 'lip_corner_distance_median': 0.043987382072537516, 'smile_median': 5.0, 'pitch_median': -5.117501465313914, 'yaw_median': 2.6669174638880087, 'roll_median': 7.247077822879174}\n"
     ]
    }
   ],
   "source": [
    "feature_storage.save_to_csv(participant_id, facial_features, prosodic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for frame in frames:\n",
    "#     frame.reset_drawable_image()\n",
    "#     # frame.draw_face_border()\n",
    "    \n",
    "#     frame.draw_selected_facial_landmarks(draw_lines=True)\n",
    "    \n",
    "#     frame.put_face_angles()\n",
    "#     # frame.draw_facial_landmarks()\n",
    "#     frame.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
