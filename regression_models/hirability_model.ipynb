{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "DROPPED_LEXICAL_COLUMNS = ['Swear', 'Numbers', 'Inhibition', 'Preceptual','Anxiety', 'Anger', 'Sadness', 'Work', 'Articles',]\n",
        "DROPPED_FACIAL_COLUMNS = [\n",
        "'average_inner_brow_height_max' , 'average_inner_brow_height_median', 'average_inner_brow_height_min',\n",
        "'average_outer_brow_height_max', \t'average_outer_brow_height_median', \t'average_outer_brow_height_min',\n",
        "'eye_open_max', 'eye_open_median', 'eye_open_min',\n",
        "'inner_lip_height_max', 'inner_lip_height_median', 'inner_lip_height_min',\n",
        "'lip_corner_distance_max', 'lip_corner_distance_median', 'lip_corner_distance_min',\n",
        "'outer_lip_height_max', 'outer_lip_height_median', 'outer_lip_height_min',\n",
        "'smile_max', 'smile_median', 'smile_min',\n",
        "'pitch_max', 'pitch_median', 'pitch_min',\n",
        "'roll_max', 'roll_median', 'roll_min',\n",
        "'yaw_max', 'yaw_median', 'yaw_min'\n",
        "                           ] \n",
        "DROPPED_PROSODIC_COLUMNS = []\n",
        "TARGET_COLUMN = 'RecommendHiring'\n",
        "GROUPS_COLUMN = 'cleaned_ids'\n",
        "SCORING_METRICS = {\n",
        "    'r2': 'r2',              \n",
        "    'mae': 'neg_mean_absolute_error', \n",
        "    # 'mse': 'neg_mean_squared_error'   \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4hl39NFMny"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFDduJ-UNVTL"
      },
      "source": [
        "## Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zff5x2vK99H_",
        "outputId": "a04675c7-e23f-4fe9-aa8f-3d82166daeab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "datasets_folder_path = \"../datasets\"\n",
        "\n",
        "features_df = pd.read_csv(os.path.join(datasets_folder_path, 'add.csv'))\n",
        "features_df = features_df.set_index('participant_id')\n",
        "\n",
        "labels_df = pd.read_csv(os.path.join(datasets_folder_path, 'turker_scores_full_interview.csv'))\n",
        "labels_df = labels_df.set_index('Participant')\n",
        "labels_df = labels_df.loc[labels_df['Worker'] == 'AGGR']\n",
        "\n",
        "features_df.index = features_df.index.str.lower()\n",
        "labels_df.index = labels_df.index.str.lower()\n",
        "indexed_combined_df = features_df.join(labels_df[[TARGET_COLUMN]], how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5XKf5J83KKc"
      },
      "source": [
        "## Fill NaN Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha83-CXp3KCu",
        "outputId": "bbb03393-2e70-4279-ed70-df37b57cabbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Print number of missing values before filling\n",
        "print(indexed_combined_df.isna().sum().sum())\n",
        "\n",
        "# Fill missing values only in numeric columns\n",
        "numeric_cols = indexed_combined_df.select_dtypes(include=['number']).columns\n",
        "indexed_combined_df[numeric_cols] = indexed_combined_df[numeric_cols].fillna(indexed_combined_df[numeric_cols].mean())\n",
        "\n",
        "# Print number of missing values after filling\n",
        "print(indexed_combined_df.isna().sum().sum())\n",
        "\n",
        "# Reset index\n",
        "combined_df = indexed_combined_df.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mVWx35ENWtk"
      },
      "source": [
        "## Drop Unnecessary Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NFfHsJANHWu8"
      },
      "outputs": [],
      "source": [
        "combined_df= combined_df.drop(columns=DROPPED_FACIAL_COLUMNS + DROPPED_LEXICAL_COLUMNS + DROPPED_PROSODIC_COLUMNS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDQ6pHknkARQ"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = combined_df.iloc[:, 2:].values\n",
        "y = combined_df.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.linear_model import LassoCV\n",
        "\n",
        "# lasso_cv = LassoCV(cv=5, random_state=42, max_iter=20000)\n",
        "# lasso_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "# coefficients = lasso_cv.coef_\n",
        "# selected_features_indices = np.where(coefficients != 0)[0]\n",
        "\n",
        "# feature_names = list(indexed_combined_df.columns[:-1])\n",
        "# selected_feature_names = [feature_names[i] for i in selected_features_indices]\n",
        "\n",
        "# selected_feature_set = set(selected_features_indices)\n",
        "# unselected_feature_names = [feature_names[i] for i in range(len(feature_names)) if i not in selected_feature_set]\n",
        "\n",
        "# print(f\"Remove {len(unselected_feature_names)} features\")\n",
        "# print(\"Unselected features:\", unselected_feature_names)\n",
        "# print(\"Selected features:\", selected_feature_names)\n",
        "# print(f\"After removal, you'll have {len(selected_feature_names)} features\")\n",
        "\n",
        "# X_train_scaled = X_train_scaled[:, selected_features_indices]\n",
        "# X_test_scaled = X_test_scaled[:, selected_features_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvciJkN0UOa"
      },
      "source": [
        "# Train SVR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "dtuJl5nq0TE6",
        "outputId": "29e327d6-818f-424a-de55-ab7d93a0cab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 (CV): 0.534 (±0.104)\n",
            "MAE (CV): -0.370 (±0.057)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score, cross_validate\n",
        "\n",
        "groups_column = combined_df[GROUPS_COLUMN].astype(str).values  \n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Scaling applied within each fold\n",
        "    ('svr', SVR(kernel='rbf'))\n",
        "])\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=GroupKFold(n_splits=5),\n",
        "    groups=groups_column,\n",
        "    scoring=SCORING_METRICS,\n",
        "    return_train_score=False  # Set to True if you also want training scores\n",
        ")\n",
        "for metric in SCORING_METRICS.keys():\n",
        "    mean_score = cv_results[f'test_{metric}'].mean()\n",
        "    std_score = cv_results[f'test_{metric}'].std()\n",
        "    print(f\"{metric.upper()} (CV): {mean_score:.3f} (±{std_score:.3f})\")\n",
        "\n",
        "    \n",
        "trained_model = pipeline.fit(X, y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
