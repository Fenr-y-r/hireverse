{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "DROPPED_LEXICAL_COLUMNS = [\n",
        "    \"Swear\",\n",
        "    \"Numbers\",\n",
        "    \"Inhibition\",\n",
        "    \"Preceptual\",\n",
        "    \"Anxiety\",\n",
        "    \"Anger\",\n",
        "    \"Sadness\",\n",
        "    \"Work\",\n",
        "    \"Articles\",\n",
        "    \"Verbs\",\n",
        "    \"Adverbs\",\n",
        "    \"Prepositions\",\n",
        "    \"Conjunctions\",\n",
        "    \"Negations\",\n",
        "]\n",
        "\n",
        "facial_features = [\n",
        "    \"average_inner_brow_height\",\n",
        "    \"average_outer_brow_height\",\n",
        "    \"eye_open\",\n",
        "    \"inner_lip_height\",\n",
        "    \"lip_corner_distance\",\n",
        "    \"outer_lip_height\",\n",
        "    \"smile\",\n",
        "    \"pitch\",\n",
        "    \"roll\",\n",
        "    \"yaw\",\n",
        "]\n",
        "stats = [\"max\", \"median\", \"min\", \"std\", \"mean\"]\n",
        "DROPPED_FACIAL_FEATURES = [\n",
        "    f\"{feature}_{stat}\" for feature in facial_features for stat in stats\n",
        "]\n",
        "\n",
        "ALREADY_NORMALIZED_FEATURES = [\n",
        "    \"average_outer_brow_height_mean\",\n",
        "    \"average_inner_brow_height_mean\",\n",
        "    \"eye_open_mean\",\n",
        "    \"inner_lip_height_mean\",\n",
        "    \"inner_lip_height_mean\",\n",
        "    \"lip_corner_distance_mean\",\n",
        "    \"average_outer_brow_height_std\",\n",
        "    \"average_inner_brow_height_std\",\n",
        "    \"eye_open_std\",\n",
        "    \"outer_lip_height_std\",\n",
        "    \"inner_lip_height_std\",\n",
        "    \"lip_corner_distance_std\",\n",
        "    \"average_outer_brow_height_min\",\n",
        "    \"average_inner_brow_height_min\",\n",
        "    \"eye_open_min\",\n",
        "    \"outer_lip_height_min\",\n",
        "    \"inner_lip_height_min\",\n",
        "    \"lip_corner_distance_min\",\n",
        "    \"average_outer_brow_height_max\",\n",
        "    \"average_inner_brow_height_max\",\n",
        "    \"eye_open_max\",\n",
        "    \"outer_lip_height_max\",\n",
        "    \"inner_lip_height_max\",\n",
        "    \"lip_corner_distance_max\",\n",
        "    \"average_outer_brow_height_median\",\n",
        "    \"average_inner_brow_height_median\",\n",
        "    \"eye_open_median\",\n",
        "    \"outer_lip_height_median\",\n",
        "    \"inner_lip_height_median\",\n",
        "    \"lip_corner_distance_median\",\n",
        "]  # these are already in [0, 1]\n",
        "\n",
        "DROPPED_PROSODIC_COLUMNS = []\n",
        "MUST_KEEP_FEATURES = [\n",
        "    \"pause_duration_avg\" \"average_outer_brow_height_mean\",\n",
        "    \"average_inner_brow_height_mean\" \"outer_lip_height_mean\" \"Duration/Filler Words\",\n",
        "]\n",
        "TARGET_COLUMN = \"RecommendHiring\"\n",
        "GROUPS_COLUMN = \"cleaned_ids\"\n",
        "\n",
        "\n",
        "def pearson_corr(y_true, y_pred):\n",
        "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
        "\n",
        "\n",
        "SCORING_METRICS = {\n",
        "    \"r2\": \"r2\",\n",
        "    \"mae\": \"neg_mean_absolute_error\",\n",
        "    \"pearson\": make_scorer(pearson_corr),  # Pearson Correlation Coefficient\n",
        "}\n",
        "\n",
        "\n",
        "MUST_KEEP_FEATURES = [\n",
        "    # \"pause_duration_avg\",\n",
        "    # \"average_outer_brow_height_mean\",\n",
        "    # \"average_inner_brow_height_mean\",\n",
        "    # \"outer_lip_height_mean\",\n",
        "    \"Duration/Filler Words\",\n",
        "]\n",
        "\n",
        "HYPERPARAMETER_TUNING_ENABLED = False\n",
        "\n",
        "\n",
        "PIPELINE_PARAMS = {  # 0.3032\n",
        "    \"feature_selection__threshold\": None,\n",
        "    \"svr__C\": 0.1,\n",
        "    \"svr__coef0\": 1.0,\n",
        "    \"svr__degree\": 3,\n",
        "    \"svr__epsilon\": 0.5,\n",
        "    \"svr__gamma\": 0.1,\n",
        "    \"svr__kernel\": \"poly\",\n",
        "    \"svr__shrinking\": True,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4hl39NFMny"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFDduJ-UNVTL"
      },
      "source": [
        "## Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zff5x2vK99H_",
        "outputId": "a04675c7-e23f-4fe9-aa8f-3d82166daeab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "datasets_folder_path = \"../datasets\"\n",
        "\n",
        "features_df = pd.read_csv(os.path.join(datasets_folder_path, \"add.csv\"))\n",
        "features_df = features_df.set_index(\"participant_id\")\n",
        "\n",
        "labels_df = pd.read_csv(\n",
        "    os.path.join(datasets_folder_path, \"turker_scores_full_interview.csv\")\n",
        ")\n",
        "labels_df = labels_df.set_index(\"Participant\")\n",
        "labels_df = labels_df.loc[labels_df[\"Worker\"] == \"AGGR\"]\n",
        "\n",
        "features_df.index = features_df.index.str.lower()\n",
        "labels_df.index = labels_df.index.str.lower()\n",
        "indexed_combined_df = features_df.join(labels_df[[TARGET_COLUMN]], how=\"left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5XKf5J83KKc"
      },
      "source": [
        "## Fill NaN Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha83-CXp3KCu",
        "outputId": "bbb03393-2e70-4279-ed70-df37b57cabbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Print number of missing values before filling\n",
        "print(indexed_combined_df.isna().sum().sum())\n",
        "\n",
        "# Fill missing values only in numeric columns\n",
        "numeric_cols = indexed_combined_df.select_dtypes(include=[\"number\"]).columns\n",
        "indexed_combined_df[numeric_cols] = indexed_combined_df[numeric_cols].fillna(\n",
        "    indexed_combined_df[numeric_cols].mean()\n",
        ")\n",
        "\n",
        "# Print number of missing values after filling\n",
        "print(indexed_combined_df.isna().sum().sum())\n",
        "\n",
        "# Reset index\n",
        "combined_df = indexed_combined_df.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mVWx35ENWtk"
      },
      "source": [
        "## Drop Unnecessary Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "NFfHsJANHWu8"
      },
      "outputs": [],
      "source": [
        "combined_df = combined_df.drop(\n",
        "    columns=DROPPED_FACIAL_FEATURES + DROPPED_LEXICAL_COLUMNS + DROPPED_PROSODIC_COLUMNS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDQ6pHknkARQ"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['f0_mean', 'f0_min', 'f0_max', 'f0_range', 'f0_sd', 'intensity_mean',\n",
            "       'intensity_min', 'intensity_max', 'intensity_range', 'intensity_sd',\n",
            "       'f1_mean', 'f1_sd', 'f2_mean', 'f2_sd', 'f3_mean', 'f3_sd',\n",
            "       'f2_f1_mean', 'f3_f1_mean', 'f2_f1_sd', 'f3_f1_sd', 'jitter', 'shimmer',\n",
            "       'percent_unvoiced', 'percent_breaks', 'pause_duration_max',\n",
            "       'pause_duration_avg', 'duration', 'Total Words', 'Unique Words',\n",
            "       'Filler Words', 'Audio Duration (s)', 'Duration/Total Words',\n",
            "       'Duration/Unique Words', 'Duration/Filler Words', 'Individual', 'We',\n",
            "       'They', 'Non-Fluences', 'PosEmotion', 'NegEmotion', 'Cognitive',\n",
            "       'Relativity', 'Quantifiers'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "X = combined_df.iloc[:, 2:-1]\n",
        "y = combined_df.iloc[:, -1]\n",
        "\n",
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvciJkN0UOa"
      },
      "source": [
        "## Pipeline Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "dtuJl5nq0TE6",
        "outputId": "29e327d6-818f-424a-de55-ab7d93a0cab2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score, cross_validate\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from models.domain_aware_selector import DomainAwareSelector\n",
        "\n",
        "groups_column = combined_df[GROUPS_COLUMN].astype(str).values\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"scale\",\n",
        "            StandardScaler(),\n",
        "            [\n",
        "                column\n",
        "                for column in X.columns\n",
        "                if column not in ALREADY_NORMALIZED_FEATURES\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "\n",
        "lasso_feature_selection_model = LassoCV(\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    max_iter=30000,\n",
        "    alphas=np.logspace(-3, 0, 30),\n",
        ")\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        # (\"preprocessor\", preprocessor),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feature_selection\", SelectFromModel(estimator=lasso_feature_selection_model)),\n",
        "        # ('feature_selection', DomainAwareSelector(\n",
        "        #     must_keep_features=MUST_KEEP_FEATURES,\n",
        "        #     selector=SelectFromModel(lasso_feature_selection_model, max_features=10),\n",
        "        # )),\n",
        "        (\"svr\", SVR(kernel=\"rbf\")),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sys\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    # Feature selection parameters\n",
        "    \"feature_selection__threshold\": [None, \"median\"],\n",
        "    # 'feature_selection__selector__threshold': [None, 'median'],\n",
        "    # SVR parameters\n",
        "    \"svr__C\": np.logspace(-2, 2, 5),  # [0.01, 0.1, 1, 10, 100]\n",
        "    \"svr__gamma\": [\"scale\", \"auto\"] + list(np.logspace(-3, 1, 5)),  # More gamma options\n",
        "    \"svr__epsilon\": [0.01, 0.1, 0.5, 1.0],\n",
        "    \"svr__kernel\": [\"rbf\", \"poly\"],  # Added poly kernel\n",
        "    \"svr__degree\": [2, 3],  # Only used for poly kernel\n",
        "    \"svr__coef0\": [0.0, 1.0],  # Important for poly kernel\n",
        "    \"svr__shrinking\": [\n",
        "        True,\n",
        "        False,\n",
        "    ],  # the difference may be subtle—often the default (shrinking=True) works well\n",
        "}\n",
        "\n",
        "if HYPERPARAMETER_TUNING_ENABLED:\n",
        "    grid_search = GridSearchCV(\n",
        "        pipeline,\n",
        "        param_grid,\n",
        "        cv=GroupKFold(n_splits=5),\n",
        "        scoring=\"r2\",\n",
        "        verbose=1,\n",
        "        n_jobs=-1,  # Uses all available CPU cores for faster execution\n",
        "    )\n",
        "    grid_search.fit(\n",
        "        X, y, groups=groups_column\n",
        "    )  # Trains models on different hyperparameter combinations using cross-validation.\n",
        "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "    print(f\"Best R² score from GridSearchCV: {grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Store Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HYPERPARAMETER_TUNING_ENABLED:\n",
        "    pipeline = grid_search.best_estimator_\n",
        "else:\n",
        "    pipeline.set_params(**PIPELINE_PARAMS)\n",
        "    pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Selected features (12):\n",
            "Selected features (Index(['f0_sd', 'intensity_mean', 'f2_mean', 'f3_mean', 'f3_sd', 'f2_f1_mean',\n",
            "       'percent_unvoiced', 'percent_breaks', 'Duration/Total Words', 'They',\n",
            "       'NegEmotion', 'Cognitive'],\n",
            "      dtype='object')):\n",
            "Unselected features :Index(['f0_mean', 'f0_min', 'f0_max', 'f0_range', 'intensity_min',\n",
            "       'intensity_max', 'intensity_range', 'intensity_sd', 'f1_mean', 'f1_sd',\n",
            "       'f2_sd', 'f3_f1_mean', 'f2_f1_sd', 'f3_f1_sd', 'jitter', 'shimmer',\n",
            "       'pause_duration_max', 'pause_duration_avg', 'duration', 'Total Words',\n",
            "       'Unique Words', 'Filler Words', 'Audio Duration (s)',\n",
            "       'Duration/Unique Words', 'Duration/Filler Words', 'Individual', 'We',\n",
            "       'Non-Fluences', 'PosEmotion', 'Relativity', 'Quantifiers'],\n",
            "      dtype='object')):\n"
          ]
        }
      ],
      "source": [
        "selected_mask = pipeline.named_steps[\"feature_selection\"].get_support()\n",
        "\n",
        "selected_features_bool_mask = pipeline.named_steps[\n",
        "    \"feature_selection\"\n",
        "].get_support()  # get_support returns a boolean mask\n",
        "selected_feature_names = X.columns[selected_features_bool_mask]\n",
        "unselected_feature_names = X.columns[~selected_features_bool_mask]\n",
        "print(f\"Number of Selected features ({len(selected_feature_names)}):\")\n",
        "print(f\"Selected features ({selected_feature_names}):\")\n",
        "print(f\"Unselected features :{unselected_feature_names}):\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation Using Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 (MC CV): 0.227 (±0.226)\n",
            "MAE (MC CV): -0.492 (±0.061)\n",
            "PEARSON (MC CV): 0.519 (±0.180)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Evaluate using R² as the metric\n",
        "cv_results = cross_validate(\n",
        "    pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=GroupKFold(n_splits=5),\n",
        "    groups=groups_column,\n",
        "    scoring=SCORING_METRICS,\n",
        "    return_train_score=False,\n",
        "    return_estimator=True,  # To access feature selection details\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 (CV): 0.227 (±0.226)\n",
            "MAE (CV): -0.492 (±0.061)\n",
            "PEARSON (CV): 0.519 (±0.180)\n"
          ]
        }
      ],
      "source": [
        "for metric in SCORING_METRICS.keys():\n",
        "    mean_score = cv_results[f\"test_{metric}\"].mean()\n",
        "    std_score = cv_results[f\"test_{metric}\"].std()\n",
        "    print(f\"{metric.upper()} (CV): {mean_score:.3f} (±{std_score:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import clone\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "N_TRIALS = 1000\n",
        "TEST_SIZE = 0.2  # 80% training, 20% testing\n",
        "r2_scores = []\n",
        "pearson_scores = []\n",
        "\n",
        "# Use GroupShuffleSplit to ensure that all data from the same participant (group) is kept together.\n",
        "gss = GroupShuffleSplit(n_splits=N_TRIALS, test_size=TEST_SIZE, random_state=42)\n",
        "\n",
        "for train_idx, test_idx in gss.split(X, y, groups=groups_column):   # runs n_splits times\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    \n",
        "    # Clone the pipeline to ensure each trial is independent\n",
        "    model = clone(pipeline)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    # Compute R² score\n",
        "    r2_scores.append(r2_score(y_test, y_pred))\n",
        "    \n",
        "    # Compute Pearson correlation coefficient\n",
        "    pearson_coef, _ = pearsonr(y_test, y_pred)\n",
        "    pearson_scores.append(pearson_coef)\n",
        "\n",
        "# Convert to numpy arrays for easier computation\n",
        "r2_scores = np.array(r2_scores)\n",
        "pearson_scores = np.array(pearson_scores)\n",
        "\n",
        "# Report the average performance and variability\n",
        "print(f\"Mean R² Score over {N_TRIALS} trials: {r2_scores.mean():.2f} (±{r2_scores.std():.2f})\")\n",
        "print(f\"Mean Pearson Correlation over {N_TRIALS} trials: {pearson_scores.mean():.2f} (±{pearson_scores.std():.2f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
